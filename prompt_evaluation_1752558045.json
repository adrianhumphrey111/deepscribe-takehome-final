{
  "prompt_analysis": {
    "overall_metrics": {
      "success_rate": 1.0,
      "average_accuracy": 0.8295296717171716,
      "average_execution_time_ms": 2952.3125,
      "total_tests": 16
    },
    "provider_comparison": {
      "openai": {
        "total": 8,
        "successful": 8,
        "accuracy_scores": [
          0.8888888888888888,
          0.8181818181818182,
          0.8749999999999999,
          0.8749999999999999,
          0.9,
          0.8124999999999999,
          0.8,
          0.6
        ],
        "confidence_scores": [
          0.9,
          0.2,
          0.8,
          0.9,
          0.9,
          0.4,
          0.5,
          0.2
        ],
        "success_rate": 1.0,
        "avg_accuracy": 0.8211963383838383,
        "avg_confidence": 0.6
      },
      "claude": {
        "total": 8,
        "successful": 8,
        "accuracy_scores": [
          0.8888888888888888,
          0.8181818181818182,
          0.8749999999999999,
          0.8749999999999999,
          0.9,
          0.8124999999999999,
          0.8,
          0.7333333333333333
        ],
        "confidence_scores": [
          0.9,
          0.2,
          0.8,
          0.8,
          0.9,
          0.4,
          0.7,
          0.3
        ],
        "success_rate": 1.0,
        "avg_accuracy": 0.837863005050505,
        "avg_confidence": 0.625
      }
    },
    "category_performance": {
      "extraction_accuracy": {
        "total": 6,
        "successful": 6,
        "accuracy_scores": [
          0.8888888888888888,
          0.8888888888888888,
          0.9,
          0.9,
          0.8,
          0.8
        ]
      },
      "edge_cases": {
        "total": 6,
        "successful": 6,
        "accuracy_scores": [
          0.8181818181818182,
          0.8181818181818182,
          0.8124999999999999,
          0.8124999999999999,
          0.6,
          0.7333333333333333
        ]
      },
      "consistency": {
        "total": 4,
        "successful": 4,
        "accuracy_scores": [
          0.8749999999999999,
          0.8749999999999999,
          0.8749999999999999,
          0.8749999999999999
        ]
      }
    },
    "consistency_score": 1.0,
    "improvement_opportunities": [
      {
        "test_case": "Creative_Interpretation_Test",
        "accuracy": 0.6,
        "errors": [
          "Confidence 0.200 outside expected range (0.3, 0.6)"
        ]
      },
      {
        "test_case": "Creative_Interpretation_Test",
        "accuracy": 0.7333333333333333,
        "errors": []
      },
      {
        "test_case": "Medication_Extraction_Challenge",
        "accuracy": 0.8,
        "errors": [
          "Confidence 0.500 outside expected range (0.8, 1.0)"
        ]
      }
    ]
  },
  "detailed_results": [
    {
      "test_case_name": "Perfect_Extraction_Oncology",
      "provider": "openai",
      "prompt_version": "current_openai",
      "success": true,
      "extraction_accuracy": 0.8888888888888888,
      "confidence_score": 0.9,
      "execution_time_ms": 3309,
      "errors": []
    },
    {
      "test_case_name": "Perfect_Extraction_Oncology",
      "provider": "claude",
      "prompt_version": "current_claude",
      "success": true,
      "extraction_accuracy": 0.8888888888888888,
      "confidence_score": 0.9,
      "execution_time_ms": 4359,
      "errors": []
    },
    {
      "test_case_name": "Minimal_Information_Edge_Case",
      "provider": "openai",
      "prompt_version": "current_openai",
      "success": true,
      "extraction_accuracy": 0.8181818181818182,
      "confidence_score": 0.2,
      "execution_time_ms": 3519,
      "errors": [
        "Confidence 0.200 outside expected range (0.3, 0.6)"
      ]
    },
    {
      "test_case_name": "Minimal_Information_Edge_Case",
      "provider": "claude",
      "prompt_version": "current_claude",
      "success": true,
      "extraction_accuracy": 0.8181818181818182,
      "confidence_score": 0.2,
      "execution_time_ms": 2411,
      "errors": [
        "Confidence 0.200 outside expected range (0.3, 0.6)"
      ]
    },
    {
      "test_case_name": "Consistency_Test_A",
      "provider": "openai",
      "prompt_version": "current_openai",
      "success": true,
      "extraction_accuracy": 0.8749999999999999,
      "confidence_score": 0.8,
      "execution_time_ms": 2881,
      "errors": []
    },
    {
      "test_case_name": "Consistency_Test_A",
      "provider": "claude",
      "prompt_version": "current_claude",
      "success": true,
      "extraction_accuracy": 0.8749999999999999,
      "confidence_score": 0.8,
      "execution_time_ms": 2187,
      "errors": []
    },
    {
      "test_case_name": "Consistency_Test_B",
      "provider": "openai",
      "prompt_version": "current_openai",
      "success": true,
      "extraction_accuracy": 0.8749999999999999,
      "confidence_score": 0.9,
      "execution_time_ms": 2607,
      "errors": []
    },
    {
      "test_case_name": "Consistency_Test_B",
      "provider": "claude",
      "prompt_version": "current_claude",
      "success": true,
      "extraction_accuracy": 0.8749999999999999,
      "confidence_score": 0.8,
      "execution_time_ms": 2129,
      "errors": []
    },
    {
      "test_case_name": "Complex_Multi_Condition",
      "provider": "openai",
      "prompt_version": "current_openai",
      "success": true,
      "extraction_accuracy": 0.9,
      "confidence_score": 0.9,
      "execution_time_ms": 4025,
      "errors": []
    },
    {
      "test_case_name": "Complex_Multi_Condition",
      "provider": "claude",
      "prompt_version": "current_claude",
      "success": true,
      "extraction_accuracy": 0.9,
      "confidence_score": 0.9,
      "execution_time_ms": 3474,
      "errors": []
    },
    {
      "test_case_name": "Ambiguous_Diagnosis_Test",
      "provider": "openai",
      "prompt_version": "current_openai",
      "success": true,
      "extraction_accuracy": 0.8124999999999999,
      "confidence_score": 0.4,
      "execution_time_ms": 2220,
      "errors": []
    },
    {
      "test_case_name": "Ambiguous_Diagnosis_Test",
      "provider": "claude",
      "prompt_version": "current_claude",
      "success": true,
      "extraction_accuracy": 0.8124999999999999,
      "confidence_score": 0.4,
      "execution_time_ms": 2181,
      "errors": []
    },
    {
      "test_case_name": "Medication_Extraction_Challenge",
      "provider": "openai",
      "prompt_version": "current_openai",
      "success": true,
      "extraction_accuracy": 0.8,
      "confidence_score": 0.5,
      "execution_time_ms": 3472,
      "errors": [
        "Confidence 0.500 outside expected range (0.8, 1.0)"
      ]
    },
    {
      "test_case_name": "Medication_Extraction_Challenge",
      "provider": "claude",
      "prompt_version": "current_claude",
      "success": true,
      "extraction_accuracy": 0.8,
      "confidence_score": 0.7,
      "execution_time_ms": 3198,
      "errors": [
        "Confidence 0.700 outside expected range (0.8, 1.0)"
      ]
    },
    {
      "test_case_name": "Creative_Interpretation_Test",
      "provider": "openai",
      "prompt_version": "current_openai",
      "success": true,
      "extraction_accuracy": 0.6,
      "confidence_score": 0.2,
      "execution_time_ms": 2803,
      "errors": [
        "Confidence 0.200 outside expected range (0.3, 0.6)"
      ]
    },
    {
      "test_case_name": "Creative_Interpretation_Test",
      "provider": "claude",
      "prompt_version": "current_claude",
      "success": true,
      "extraction_accuracy": 0.7333333333333333,
      "confidence_score": 0.3,
      "execution_time_ms": 2462,
      "errors": []
    }
  ]
}